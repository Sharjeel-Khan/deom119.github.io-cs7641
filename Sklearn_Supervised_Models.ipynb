{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('SpotifyFeatures.csv')\n",
    "df['popularity'] = df['popularity']/100\n",
    "df = df.drop_duplicates(subset=['track_name', 'artist_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df[['popularity', \n",
    "              'acousticness', \n",
    "              'danceability', \n",
    "              'duration_ms',\n",
    "              'energy',\n",
    "              'instrumentalness', \n",
    "              'liveness', \n",
    "              'loudness', \n",
    "              'speechiness',\n",
    "              'tempo',\n",
    "              'valence',\n",
    "             ]].corr()\n",
    "corr_df = corr_df.apply(lambda x: round(x, 2))\n",
    "import seaborn as sns\n",
    "sns.heatmap(corr_df, \n",
    "        xticklabels=corr_df.columns,\n",
    "        yticklabels=corr_df.columns, vmax=1.0, vmin=-1.0, annot=True, cmap='Blues').set_title('Correlation matrix for music features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df,pd.get_dummies(df['mode'])),1)\n",
    "df = pd.concat((df,pd.get_dummies(df['key'])),1)\n",
    "df = pd.concat((df,pd.get_dummies(df['time_signature'])),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.columns != 'genre']\n",
    "df = df.loc[:, df.columns != 'artist_name']\n",
    "df = df.loc[:, df.columns != 'track_name']\n",
    "df = df.loc[:, df.columns != 'track_id']\n",
    "df = df.loc[:, df.columns != 'mode']\n",
    "df = df.loc[:, df.columns != 'key']\n",
    "df = df.loc[:, df.columns != 'time_signature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "x_data = df.loc[:, df.columns != 'popularity']\n",
    "\n",
    "\n",
    "y_data = df['popularity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=100)\n",
    "knn.fit(X_train, y_train)\n",
    "print(knn.score(X_test, y_test))\n",
    "print(mean_squared_error(knn.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "print(lin_reg.score(X_test, y_test))\n",
    "print(mean_squared_error(lin_reg.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor(n_estimators=50,\n",
    "                                     max_depth=10,\n",
    "                                     )\n",
    "random_forest.fit(X_train, y_train)\n",
    "print(random_forest.score(X_test, y_test))\n",
    "print(mean_squared_error(random_forest.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(x_data.columns[np.argsort(random_forest.feature_importances_)[::-1][:10]], \n",
    "       random_forest.feature_importances_[np.argsort(random_forest.feature_importances_)[::-1][:10]])\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(rotation=60)\n",
    "plt.title(\"Feature importances for random forest model\")\n",
    "plt.ylabel(\"Feature importance\")\n",
    "plt.savefig(\"images/feature_importances_random_forest.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree = DecisionTreeRegressor(max_depth=10,)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "print(decision_tree.score(X_test, y_test))\n",
    "print(mean_squared_error(decision_tree.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVR\n",
    "# svm = LinearSVR(C=1, max_iter=10000)\n",
    "# svm.fit(X_train, y_train)\n",
    "# print(svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scoring = {'R2': make_scorer(r2_score), 'MSE': make_scorer(mean_squared_error)}\n",
    "\n",
    "models = {\"Linear_Regression\": LinearRegression(),\n",
    "          \"KNN\": KNeighborsRegressor(n_neighbors=100),\n",
    "          \"Random_Forest\": RandomForestRegressor(n_estimators=50,\n",
    "                                          max_depth=10,\n",
    "                                          ),\n",
    "          \"Decision_Tree\": DecisionTreeRegressor(max_depth=10,)\n",
    "         }\n",
    "\n",
    "R2_scores = []\n",
    "RMSE_scores = []\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_validate(model, x_data, y_data, cv=10, n_jobs=2, scoring =scoring, return_train_score=False)\n",
    "    print(f\"{name} R2 score: {cv_scores['test_R2'].mean()}\")\n",
    "    print(f\"{name} RMSE score: {cv_scores['test_MSE'].mean() ** (1/2)}\")\n",
    "    R2_scores.append(cv_scores['test_R2'].mean())\n",
    "    RMSE_scores.append(cv_scores['test_MSE'].mean()** (1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(models.keys(), R2_scores)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.title(\"R2 Score for each model\")\n",
    "plt.ylabel(\"R2 Score\")\n",
    "plt.savefig(\"images/r2_bar_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.bar(models.keys(), RMSE_scores)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"RMSE for each model\")\n",
    "\n",
    "plt.savefig(\"images/rmse_bar_plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
